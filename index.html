<!DOCTYPE html>
<html>
  <head>
    <title>Teachable Machine 基本サンプル</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
  </head>
  <body>

    <div>Teachable Machine Audio Model</div>
    <input type="text" id="token">
    <button type="button" onclick="setLightStatus('on', '00FF00')">light</button><br>
    <button type="button" onclick="init()">Start</button>
    <div id="label-container"></div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

    <script type="text/javascript">
        // more documentation available at
        // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

        // the link to your model provided by Teachable Machine export panel
        const URL = "https://teachablemachine.withgoogle.com/models/xV41ylkJr/";

        async function createModel() {
            const checkpointURL = URL + "model.json"; // model topology
            const metadataURL = URL + "metadata.json"; // model metadata

            const recognizer = speechCommands.create(
                "BROWSER_FFT", // fourier transform type, not useful to change
                undefined, // speech commands vocabulary feature, not useful for your models
                checkpointURL,
                metadataURL);

            // check that model and metadata are loaded via HTTPS requests.
            await recognizer.ensureModelLoaded();

            return recognizer;
        }

        async function init() {
            const recognizer = await createModel();
            const classLabels = recognizer.wordLabels(); // get class labels
            const labelContainer = document.getElementById("label-container");
            for (let i = 0; i < classLabels.length; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }

            // listen() takes two arguments:
            // 1. A callback function that is invoked anytime a word is recognized.
            // 2. A configuration object with adjustable fields
            recognizer.listen(result => {
                const scores = result.scores; // probability of prediction for each class
                // render the probability scores per class
                for (let i = 0; i < classLabels.length; i++) {
                    const score = result.scores[i].toFixed(2);
                    if (classLabels[i] != '_background_noise_' && score > 0.8) {
                      if (classLabels[i] == 'amazing') {
                        console.log("amazing:" + score);
                        setLightStatus('on', 'FF0000');
                        return;
                      } else if (classLabels[i] == 'soon') {
                        console.log("soon");
                        setLightStatus('on', '0000FF');
                        return;
                      } else if (classLabels[i] == 'zazaza') {
                        console.log("zazaza");
                        setLightStatus('on', '00FF00');
                        return;
                      } else if (classLabels[i] == 'yubi') {
                        console.log("yubi");
                        setLightStatus('off', 'FF0000');
                        return;
                      }
                    }
                    const classPrediction = classLabels[i] + ": " + score;
                    console.log("class:" + classPrediction);
                    labelContainer.childNodes[i].innerHTML = classPrediction;
                }
            }, {
                includeSpectrogram: true, // in case listen should return result.spectrogram
                probabilityThreshold: 0.75,
                invokeCallbackOnNoiseAndUnknown: true,
                overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
            });

            // Stop the recognition in 5 seconds.
            // setTimeout(() => recognizer.stopListening(), 5000);
        }

        async function setLightStatus(power, color) {
          let xhr = new XMLHttpRequest();
          const token = document.getElementById('token').value;

          // 3. ネットワーク経由でリクエスト送信
          // 2. 設定: URL /article/.../load に対する GET-リクエスト
          xhr.open('PUT', 'https://api.lifx.com/v1/lights/all/state');
          xhr.setRequestHeader('Content-Type', 'application/json');
          xhr.setRequestHeader('Authorization', 'Bearer ' + token);

          xhr.send(JSON.stringify({
            'power': power,
            'color': color,
            'brightness': 1.0
          }));

          // 4. レスポンスを受け取った後に呼び出されます
          xhr.onload = function() {
            if (xhr.status != 207) { // レスポンスの HTTP ステータスを解析
              console.log(`Error ${xhr.status}: ${xhr.statusText}`); // e.g. 404: Not Found
            } else { // show the result
              console.log(`Done, got ${xhr.response.length} bytes`); // responseText is the server
            }
          };
          xhr.onreadystatechange = function() {

          }
        }
    </script>
  </body>
</html>
